# Detection of Antisocial Behavior using LLMs

This repository contains all files related to my bachelor thesis project on detecting antisocial behavior using Large Language Models (LLMs).

## 📁 Contents

- `model/` – Fine-tuned and base LLMs (quantized in `q4_k_m` format).
- `training/` – Code used to fine-tune the models.
- `testing/` – Code to test the trained models on new data.
- `data_prep/` – Scripts for cleaning and preparing the dataset.
- `prompts/` – Prompt templates for inference (with and without SYSTEM message).

Everything here was used to train, test, and experiment with LLMs for toxic comment classification.

