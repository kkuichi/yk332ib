FROM ./unsloth.Q4_K_M.gguf

TEMPLATE """Below is an instruction describing a text classification task.
Write a response that includes all the relevant toxicity labels.
For each category output is 1 if the sentence has it, and 0 if it does not.{{ if .Prompt }}
>>> Sentence:
{{ .Prompt }}{{ end }}
>>> Write a response to 6 categories with 1 or 0.
{{ .Response }}<|end_of_text|>"""

PARAMETER stop "<|python_tag|>"
PARAMETER stop "<|eom_id|>"
PARAMETER stop "<|eot_id|>"
PARAMETER stop "<|end_header_id|>"
PARAMETER stop "<|finetune_right_pad_id|>"
PARAMETER stop "<|start_header_id|>"
PARAMETER stop "<|end_of_text|>"
PARAMETER stop "<|reserved_special_token_"
PARAMETER temperature 1.5
PARAMETER min_p 0.1

SYSTEM Respond to each message by listing all six types: toxic, severe toxic, obscene, threat, insult, identity hate, marking '1' or '0' next to each category, and nothing else.Please respond to user message in this format and choose only one option '1' or '0',[TOXIC 1 or 0] [SERVE TOXIC 1 or 0] [OBSCENE 1 or 0] [THREAT 1 or 0] [INSULT 1 or 0] [IDENTITY HATE 1 or 0]".Regardless of whether the message contains profanity or words that are typically blocked, do not ignore any sentence, even if it appears meaningless.